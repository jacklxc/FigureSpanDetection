{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/xiangcili/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from util import readAllSeqLabelFigure,cleanFigureAnnotation, blockBIO, sortFigureAnnotation, \\\n",
    "    flatten,BIO2FigureLabel, read_passages\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np\n",
    "\n",
    "from figureSpanExtractor import extractDocumentFigureSpan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_input_file = \"test_coronavirus.txt\"\n",
    "inference_discourse_label_file = \"test.out\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_str_seqs, _ = read_passages(inference_input_file, False)\n",
    "test_label_seqs, _ = read_passages(inference_discourse_label_file, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_figure_appearances = extractDocumentFigureSpan(test_str_seqs)\n",
    "test_figure_appearances = sortFigureAnnotation(test_figure_appearances, placeholder = \"NaN\")\n",
    "test_figure_appearances = cleanFigureAnnotation(test_figure_appearances, placeholder=\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(trainfilename):\n",
    "    str_seqs, label_seqs, figure_seqs, figure_appearances, str_seq_lens = readAllSeqLabelFigure(trainfilename)\n",
    "    figure_appearances = sortFigureAnnotation(figure_appearances, placeholder = \"NaN\")\n",
    "    figure_seqs = sortFigureAnnotation(figure_seqs, placeholder = \"NaN\")\n",
    "    figure_appearances = cleanFigureAnnotation(figure_appearances, placeholder=\"NaN\")\n",
    "    figure_seqs = cleanFigureAnnotation(figure_seqs, placeholder=\"NaN\")\n",
    "    figure_BIO = blockBIO(figure_seqs, placeholder=\"NaN\")\n",
    "    return str_seqs, label_seqs, figure_seqs, figure_appearances, figure_BIO, str_seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the directory of the tsv files here.\n",
    "trainfilename = \"train+test/all/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train+test/all/19734906_spans.tsv 14 14\n",
      "train+test/all/10704436_spans.tsv 5 19\n",
      "train+test/all/10087260_spans.tsv 12 31\n",
      "train+test/all/15314656_spans.tsv 5 36\n",
      "train+test/all/9128250_spans.tsv 10 46\n",
      "train+test/all/18583988_spans_test.tsv 8 54\n",
      "train+test/all/11238593_spans.tsv 8 62\n",
      "train+test/all/10790433_spans.tsv 15 77\n",
      "train+test/all/10085298_spans.tsv 17 94\n",
      "train+test/all/14707117_spans.tsv 12 106\n",
      "train+test/all/16729043_spans_test.tsv 15 121\n",
      "train+test/all/16602827_spans.tsv 21 142\n",
      "train+test/all/9625767_spans.tsv 6 148\n",
      "train+test/all/9971737_spans.tsv 14 162\n",
      "train+test/all/18604198_spans.tsv 19 181\n",
      "train+test/all/11777939_spans.tsv 13 194\n",
      "train+test/all/16848641_spans.tsv 13 207\n",
      "train+test/all/17276402_spans.tsv 6 213\n",
      "train+test/all/24835508_spans.tsv 6 219\n",
      "train+test/all/9700154_spans.tsv 14 233\n"
     ]
    }
   ],
   "source": [
    "str_seqs, label_seqs, figure_seqs, figure_appearances, figure_BIO, str_seq_lens = process(trainfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"B\",\"I\",\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(clause, N=1):\n",
    "    words = clause.split()\n",
    "    n_grams = []\n",
    "    n_gram = [\"#\"] * N\n",
    "    for i, word in enumerate(words):\n",
    "        n_gram = n_gram[1:]\n",
    "        n_gram.append(word)\n",
    "        n_grams.append(\" \".join(n_gram))\n",
    "    for n in range(N-1):\n",
    "        n_gram = n_gram[1:]\n",
    "        n_gram.append(\"#\")\n",
    "        n_grams.append(\" \".join(n_gram))\n",
    "    return set(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2features(paragraph, discourses ,appearances, i):\n",
    "    sentence = paragraph[i]\n",
    "    discourse = discourses[i]\n",
    "    appearance = appearances[i]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'unigrams': n_grams(sentence, N=1),\n",
    "        'bigrams': n_grams(sentence, N=2),\n",
    "        'trigrams': n_grams(sentence, N=3),\n",
    "        'BOP': False,\n",
    "        'EOP': False,\n",
    "        'discourse': discourse, # Include scientific discourses as input features.\n",
    "        'appearance': appearance\n",
    "    }\n",
    "    \n",
    "    if i > 0:\n",
    "        sentence1 = paragraph[i-1]\n",
    "        discourse1 = discourses[i-1]\n",
    "        appearance1 = appearances[i-1]\n",
    "        features.update({\n",
    "            '-1:unigrams': n_grams(sentence1, N=1),\n",
    "            '-1:bigrams': n_grams(sentence1, N=2),\n",
    "            '-1:trigrams': n_grams(sentence1, N=3),\n",
    "            '-1:discourse': discourse1,\n",
    "            '-1:appearance': appearance1\n",
    "        })\n",
    "    else:\n",
    "        features['BOP'] = True\n",
    "\n",
    "    if i < len(paragraph)-1:\n",
    "        sentence1 = paragraph[i+1]\n",
    "        discourse1 = discourses[i+1]\n",
    "        appearance1 = appearances[i+1]\n",
    "        features.update({\n",
    "            '+1:unigrams': n_grams(sentence1, N=1),\n",
    "            '+1:bigrams': n_grams(sentence1, N=2),\n",
    "            '+1:trigrams': n_grams(sentence1, N=3),\n",
    "            '+1:discourse': discourse1,\n",
    "            '+1:appearance': appearance1\n",
    "        })\n",
    "    else:\n",
    "        features['EOP'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraph2features(paragraph, label_para, appearance_para):\n",
    "    return [sentence2features(paragraph, label_para, appearance_para, i) for i in range(len(paragraph))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [paragraph2features(p, label_para, appearance_para) for p, label_para, appearance_para in zip(str_seqs, label_seqs, figure_appearances)]\n",
    "y_train = figure_BIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrs = RandomizedSearchCV(crf, params_space,\\n                        cv=5,\\n                        verbose=1,\\n                        n_jobs=-1,\\n                        n_iter=10,\\n                        scoring=f1_scorer)\\nrs.fit(X_train, y_train)\\ncrf = rs.best_estimator_\\n\\nprint('best params:', rs.best_params_)\\nprint('best CV score:', rs.best_score_)\\nprint('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))\\n\""
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use this code to search optimal hyper parameters, but empirically the hyperparameter of CRF does not affect the results much.\n",
    "\"\"\"\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=5,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=10,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)\n",
    "crf = rs.best_estimator_\n",
    "\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.3, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    c1 = 0.3,\n",
    "    c2 = 0.1\n",
    ")\n",
    "crf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [paragraph2features(p, label_para, appearance_para) for p, label_para, appearance_para in zip(test_str_seqs, test_label_seqs, test_figure_appearances)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_figure = BIO2FigureLabel(y_pred, test_figure_appearances, placeholder=\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [['NaN'], ['NaN']]\n",
      "2 [['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "3 [['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "4 [['NaN'], ['NaN']]\n",
      "5 [['NaN'], ['NaN']]\n",
      "6 [['NaN'], ['NaN'], ['NaN']]\n",
      "7 [['NaN'], ['NaN']]\n",
      "8 [['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "9 [['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "10 [['NaN'], ['NaN'], ['NaN']]\n",
      "11 [['NaN'], ['NaN'], ['NaN'], ['1'], ['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "12 [['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "13 [['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "14 [['2a', '2b'], ['2a', '2b']]\n",
      "15 [['NaN'], ['NaN']]\n",
      "16 [['NaN'], ['1', '2'], ['1', '2'], ['1', '2'], ['1', '2'], ['1', '2'], ['1', '2']]\n",
      "17 [['NaN'], ['NaN']]\n",
      "18 [['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN'], ['3'], ['3'], ['3']]\n",
      "19 [['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "20 [['NaN'], ['NaN'], ['NaN']]\n",
      "21 [['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "22 [['NaN'], ['NaN']]\n",
      "23 [['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "24 [['NaN']]\n",
      "25 [['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "26 [['NaN']]\n",
      "27 [['NaN'], ['NaN'], ['NaN']]\n",
      "28 [['NaN'], ['NaN']]\n",
      "29 [['NaN'], ['NaN'], ['NaN'], ['NaN'], ['NaN']]\n",
      "30 [['NaN']]\n"
     ]
    }
   ],
   "source": [
    "for i, para in enumerate(pred_figure):\n",
    "    print(i+1, para)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_file = \"test_span.txt\"\n",
    "with open(out_file, \"w\") as f:\n",
    "    for para_seq, para_label, para_span in zip(test_str_seqs, test_label_seqs, pred_figure):\n",
    "        for seq, label, span in zip(para_seq, para_label, para_span):\n",
    "            f.write(seq+\"\\t\"+label+\"\\t\"+\"|\".join(span)+\"\\n\")\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
