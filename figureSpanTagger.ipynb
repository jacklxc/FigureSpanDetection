{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/lixiangci/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from util import readAllSeqLabelFigure,cleanFigureAnnotation, blockBIO, sortFigureAnnotation, \\\n",
    "    flatten, candidatesPerParagraph,BIO2FigureLabel, computeF1, computePaperF1\n",
    "\n",
    "from sklearn_crfsuite import CRF\n",
    "from sklearn_crfsuite import metrics\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import scipy.stats\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(trainfilename):\n",
    "    original_str_seqs, label_seqs, original_figure_seqs, original_figure_appearances, str_seq_lens = readAllSeqLabelFigure(trainfilename)\n",
    "    original_figure_appearances = sortFigureAnnotation(original_figure_appearances, placeholder = \"NaN\")\n",
    "    original_figure_seqs = sortFigureAnnotation(original_figure_seqs, placeholder = \"NaN\")\n",
    "    original_candidate_seqs = candidatesPerParagraph(original_figure_seqs)\n",
    "    original_figure_appearances = cleanFigureAnnotation(original_figure_appearances, placeholder=\"NaN\")\n",
    "    original_figure_seqs = cleanFigureAnnotation(original_figure_seqs, placeholder=\"NaN\")\n",
    "    str_seqs, figure_seqs, figure_appearances, candidate_seqs = original_str_seqs, original_figure_seqs, original_figure_appearances, original_candidate_seqs\n",
    "    candidate_seqs = candidatesPerParagraph(figure_seqs)\n",
    "    figure_BIO = blockBIO(figure_seqs, placeholder=\"NaN\")\n",
    "    return str_seqs, label_seqs, figure_seqs, figure_appearances, candidate_seqs, figure_BIO, original_figure_appearances, original_figure_seqs, str_seq_lens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Put the directory of the tsv files here.\n",
    "trainfilename = \"/Users/lixiangci/Downloads/train+test/train+dev/\"\n",
    "testfilename = \"/Users/lixiangci/Downloads/train+test/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/lixiangci/Downloads/train+test/train+dev/19734906_spans.tsv 14 14\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/10087260_spans.tsv 12 26\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/15314656_spans.tsv 5 31\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/9128250_spans.tsv 10 41\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/11238593_spans.tsv 8 49\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/10790433_spans.tsv 15 64\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/10085298_spans.tsv 17 81\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/14707117_spans.tsv 12 93\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/16602827_spans.tsv 21 114\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/9625767_spans.tsv 6 120\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/18604198_spans.tsv 19 139\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/11777939_spans.tsv 13 152\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/16848641_spans.tsv 13 165\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/17276402_spans.tsv 6 171\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/24835508_spans.tsv 6 177\n",
      "/Users/lixiangci/Downloads/train+test/train+dev/9700154_spans.tsv 14 191\n",
      "/Users/lixiangci/Downloads/train+test/test/10704436_spans.tsv 5 5\n",
      "/Users/lixiangci/Downloads/train+test/test/9971737_spans.tsv 14 19\n"
     ]
    }
   ],
   "source": [
    "str_seqs, label_seqs, figure_seqs, figure_appearances, candidate_seqs, figure_BIO, original_figure_appearances, original_figure_seqs, str_seq_lens = process(trainfilename)\n",
    "test_str_seqs, test_label_seqs, test_figure_seqs, test_figure_appearances, test_candidate_seqs, test_figure_BIO, test_original_figure_appearances, test_original_figure_seqs, test_str_seq_lens = process(testfilename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"B\",\"I\",\"O\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def n_grams(clause, N=1):\n",
    "    words = clause.split()\n",
    "    n_grams = []\n",
    "    n_gram = [\"#\"] * N\n",
    "    for i, word in enumerate(words):\n",
    "        n_gram = n_gram[1:]\n",
    "        n_gram.append(word)\n",
    "        n_grams.append(\" \".join(n_gram))\n",
    "    for n in range(N-1):\n",
    "        n_gram = n_gram[1:]\n",
    "        n_gram.append(\"#\")\n",
    "        n_grams.append(\" \".join(n_gram))\n",
    "    return set(n_grams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentence2features(paragraph, discourses, candidates ,appearances, i):\n",
    "    sentence = paragraph[i]\n",
    "    discourse = discourses[i]\n",
    "    appearance = appearances[i]\n",
    "    features = {\n",
    "        'bias': 1.0,\n",
    "        'unigrams': n_grams(sentence, N=1),\n",
    "        'bigrams': n_grams(sentence, N=2),\n",
    "        'trigrams': n_grams(sentence, N=3),\n",
    "        'BOP': False,\n",
    "        'EOP': False,\n",
    "        'discourse': discourse, # Include scientific discourses as input features.\n",
    "        #'candidates': set(candidates),\n",
    "        'appearance': appearance\n",
    "    }\n",
    "    \n",
    "    if i > 0:\n",
    "        sentence1 = paragraph[i-1]\n",
    "        discourse1 = discourses[i-1]\n",
    "        appearance1 = appearances[i-1]\n",
    "        features.update({\n",
    "            '-1:unigrams': n_grams(sentence1, N=1),\n",
    "            '-1:bigrams': n_grams(sentence1, N=2),\n",
    "            '-1:trigrams': n_grams(sentence1, N=3),\n",
    "            '-1:discourse': discourse1,\n",
    "            '-1:appearance': appearance1\n",
    "        })\n",
    "    else:\n",
    "        features['BOP'] = True\n",
    "\n",
    "    if i < len(paragraph)-1:\n",
    "        sentence1 = paragraph[i+1]\n",
    "        discourse1 = discourses[i+1]\n",
    "        appearance1 = appearances[i+1]\n",
    "        features.update({\n",
    "            '+1:unigrams': n_grams(sentence1, N=1),\n",
    "            '+1:bigrams': n_grams(sentence1, N=2),\n",
    "            '+1:trigrams': n_grams(sentence1, N=3),\n",
    "            '+1:discourse': discourse1,\n",
    "            '+1:appearance': appearance1\n",
    "        })\n",
    "    else:\n",
    "        features['EOP'] = True\n",
    "\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def paragraph2features(paragraph, label_para, candidate_para, appearance_para):\n",
    "    return [sentence2features(paragraph, label_para, candidate_para, appearance_para, i) for i in range(len(paragraph))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = [paragraph2features(p, label_para, candidate_para, appearance_para) for p, label_para, candidate_para, appearance_para in zip(str_seqs, label_seqs, candidate_seqs, figure_appearances)]\n",
    "y_train = figure_BIO\n",
    "\n",
    "X_test = [paragraph2features(p, label_para, candidate_para, appearance_para) for p, label_para, candidate_para, appearance_para in zip(test_str_seqs, test_label_seqs, test_candidate_seqs, test_figure_appearances)]\n",
    "y_test = test_figure_BIO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_space = {\n",
    "    'c1': scipy.stats.expon(scale=0.5),\n",
    "    'c2': scipy.stats.expon(scale=0.05),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1_scorer = make_scorer(metrics.flat_f1_score,\n",
    "                        average='weighted', labels=labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nrs = RandomizedSearchCV(crf, params_space,\\n                        cv=5,\\n                        verbose=1,\\n                        n_jobs=-1,\\n                        n_iter=10,\\n                        scoring=f1_scorer)\\nrs.fit(X_train, y_train)\\ncrf = rs.best_estimator_\\n\\nprint('best params:', rs.best_params_)\\nprint('best CV score:', rs.best_score_)\\nprint('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))\\n\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# You can use this code to search optimal hyper parameters, but empirically the hyperparameter of CRF does not affect the results much.\n",
    "\"\"\"\n",
    "rs = RandomizedSearchCV(crf, params_space,\n",
    "                        cv=5,\n",
    "                        verbose=1,\n",
    "                        n_jobs=-1,\n",
    "                        n_iter=10,\n",
    "                        scoring=f1_scorer)\n",
    "rs.fit(X_train, y_train)\n",
    "crf = rs.best_estimator_\n",
    "\n",
    "print('best params:', rs.best_params_)\n",
    "print('best CV score:', rs.best_score_)\n",
    "print('model size: {:0.2f}M'.format(rs.best_estimator_.size_ / 1000000))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CRF(algorithm='lbfgs', all_possible_states=None, all_possible_transitions=True,\n",
       "    averaging=None, c=None, c1=0.3, c2=0.1, calibration_candidates=None,\n",
       "    calibration_eta=None, calibration_max_trials=None, calibration_rate=None,\n",
       "    calibration_samples=None, delta=None, epsilon=None, error_sensitive=None,\n",
       "    gamma=None, keep_tempfiles=None, linesearch=None, max_iterations=100,\n",
       "    max_linesearch=None, min_freq=None, model_filename=None, num_memories=None,\n",
       "    pa_type=None, period=None, trainer_cls=None, variance=None, verbose=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "crf = CRF(\n",
    "    algorithm='lbfgs',\n",
    "    max_iterations=100,\n",
    "    all_possible_transitions=True,\n",
    "    c1 = 0.3,\n",
    "    c2 = 0.1\n",
    ")\n",
    "crf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_f1(label_seqs,pred_label_seqs):\n",
    "    true_label = flatten(label_seqs)\n",
    "    pred_label = flatten(pred_label_seqs)\n",
    "\n",
    "    f1 = f1_score(true_label,pred_label,average=\"weighted\")\n",
    "    return f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_pred = crf.predict(X_train)\n",
    "y_pred = crf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set BIO F1 score: 1.0\n"
     ]
    }
   ],
   "source": [
    "f1 = test_f1(y_train,y_train_pred)\n",
    "print(\"Training set BIO F1 score:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set BIO F1 score: 0.8159948979591838\n"
     ]
    }
   ],
   "source": [
    "f1 = test_f1(y_test,y_pred)\n",
    "print(\"Test set BIO F1 score:\",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred_figure = BIO2FigureLabel(y_train_pred, original_figure_appearances, placeholder=\"NaN\")\n",
    "test_pred_figure = BIO2FigureLabel(y_pred, test_original_figure_appearances, placeholder=\"NaN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstructed test F1 score: 0.8071524064171123\n"
     ]
    }
   ],
   "source": [
    "prev = 0\n",
    "paperF1s = []\n",
    "for seq_len in test_str_seq_lens:\n",
    "    paperF1 = computePaperF1(test_original_figure_seqs, test_pred_figure, prev, prev + seq_len)\n",
    "    paperF1s.append(paperF1)\n",
    "    prev += seq_len\n",
    "print(\"Reconstructed test F1 score:\", np.mean(paperF1s))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
